{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Day_89_HW.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"LgDgpaITJ_g2","colab_type":"text"},"source":["## Work\n","1. 請自行定義一個 loss function, 為 0.3 * focal loss + 0.7 cross-entropy，訓練並比較結果\n"]},{"cell_type":"code","metadata":{"id":"QHcjSrQzJ_g4","colab_type":"code","outputId":"edb009a3-b914-459a-8c13-674621b4d85f","executionInfo":{"status":"ok","timestamp":1564651653126,"user_tz":-480,"elapsed":2372,"user":{"displayName":"Po-Lung Chiu","photoUrl":"https://lh6.googleusercontent.com/-R0yKMvbA83Q/AAAAAAAAAAI/AAAAAAAAB3U/4tuOyurSQTk/s64/photo.jpg","userId":"02092798968953226767"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import keras\n","import itertools\n","\n","from keras.backend.tensorflow_backend import set_session\n","import tensorflow as tf\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #有多个GPU时可以指定只使用第几号GPU\n","config = tf.ConfigProto()\n","config.allow_soft_placement=True #允许动态放置张量和操作符\n","#config.gpu_options.per_process_gpu_memory_fraction = 0.4 #最多使用40%GPU内存\n","config.gpu_options.allow_growth=True   #初始化时不全部占满GPU显存, 按需分配 \n","sess = tf.Session(config = config)\n","set_session(sess)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5V2o3UaxJ_g7","colab_type":"code","outputId":"0ecda74b-e646-452a-8d37-922275a2f930","executionInfo":{"status":"ok","timestamp":1564651662773,"user_tz":-480,"elapsed":8813,"user":{"displayName":"Po-Lung Chiu","photoUrl":"https://lh6.googleusercontent.com/-R0yKMvbA83Q/AAAAAAAAAAI/AAAAAAAAB3U/4tuOyurSQTk/s64/photo.jpg","userId":"02092798968953226767"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["train, test = keras.datasets.cifar10.load_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 5s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DgBGzTfdJ_g-","colab_type":"code","colab":{}},"source":["## 資料前處理\n","def preproc_x(x, flatten=True):\n","    x = x / 255.\n","    if flatten:\n","        x = x.reshape((len(x), -1))\n","    return x\n","\n","def preproc_y(y, num_classes=10):\n","    if y.shape[-1] == 1:\n","        y = keras.utils.to_categorical(y, num_classes)\n","    return y    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwQMVGLqJ_hB","colab_type":"code","colab":{}},"source":["x_train, y_train = train\n","x_test, y_test = test\n","\n","# Preproc the inputs\n","x_train = preproc_x(x_train)\n","x_test = preproc_x(x_test)\n","\n","# Preprc the outputs\n","y_train = preproc_y(y_train)\n","y_test = preproc_y(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTIAbO_VJ_hD","colab_type":"code","colab":{}},"source":["from keras.layers import BatchNormalization\n","\n","\"\"\"\n","建立神經網路，並加入 BN layer\n","\"\"\"\n","def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n","    input_layer = keras.layers.Input(input_shape)\n","    \n","    for i, n_units in enumerate(num_neurons):\n","        if i == 0:\n","            x = keras.layers.Dense(units=n_units, \n","                                   activation=\"relu\", \n","                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n","            x = BatchNormalization()(x)\n","        else:\n","            x = keras.layers.Dense(units=n_units, \n","                                   activation=\"relu\", \n","                                   name=\"hidden_layer\"+str(i+1))(x)\n","            x = BatchNormalization()(x)\n","    \n","    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n","    \n","    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0BdeeeTJ_hG","colab_type":"code","colab":{}},"source":["## 超參數設定\n","LEARNING_RATE = 1e-3\n","EPOCHS = 25\n","BATCH_SIZE = 1024\n","MOMENTUM = 0.95"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"shKzerhXJ_hJ","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import keras.backend as K\n","\n","\"\"\"Code Here\n","撰寫一個 loss function, 使其可以結合 focal loss 與 crossentropy loss\n","\"\"\"\n","\n"," \n","def combined_loss(y_true, y_pred, weight=0.3, e=0.1, gamma=2., alpha=4.):\n","    crossentropy = (1-e)*K.categorical_crossentropy(y_pred,y_true) + e*K.categorical_crossentropy(y_pred, K.ones_like(y_pred)/10)\n","    \n","    gamma = float(gamma)\n","    alpha = float(alpha)\n","    def focal_loss_fixed(y_true, y_pred):\n","        \"\"\"Focal loss for multi-classification\n","        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n","        \"\"\"\n","        epsilon = 1e-8\n","        y_true = tf.convert_to_tensor(y_true, tf.float32)\n","        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n","\n","        model_out = tf.add(y_pred, epsilon)\n","        ce = tf.multiply(y_true, -tf.log(model_out))\n","        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n","        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n","        reduced_fl = tf.reduce_max(fl, axis=1)\n","        return tf.reduce_mean(reduced_fl)\n","    \n","    return weight * focal_loss_fixed + (1-weight) * crossentropy\n","\n","ce_weights_list = [0., 0.3, 0.5, 0.7, 1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"nKOxmGGlJ_hL","colab_type":"code","outputId":"a0e71f4d-9d07-4267-f959-1389cceeb747","executionInfo":{"status":"error","timestamp":1564651898603,"user_tz":-480,"elapsed":839,"user":{"displayName":"Po-Lung Chiu","photoUrl":"https://lh6.googleusercontent.com/-R0yKMvbA83Q/AAAAAAAAAAI/AAAAAAAAB3U/4tuOyurSQTk/s64/photo.jpg","userId":"02092798968953226767"}},"colab":{"base_uri":"https://localhost:8080/","height":774}},"source":["import itertools\n","results = {}\n","\n","for i, ce_w in enumerate(ce_weights_list):\n","    print(\"Numbers of exp: %i, ce_weight: %.2f\" % (i, ce_w))\n","\n","    model = build_mlp(input_shape=x_train.shape[1:])\n","    model.summary()\n","    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n","    \"\"\"Code Here\n","    將自定義的 loss function 加入模型\n","    \"\"\"\n","    model.compile(loss=combined_loss, metrics=[\"accuracy\"], optimizer=optimizer)\n","\n","    model.fit(x_train, y_train, \n","              epochs=EPOCHS, \n","              batch_size=BATCH_SIZE, \n","              validation_data=(x_test, y_test), \n","              shuffle=True\n","             )\n","    \n","    # Collect results\n","    exp_name_tag = (\"exp-%s\" % (i))\n","    results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"],\n","                             'valid-loss': model.history.history[\"val_loss\"],\n","                             'train-acc': model.history.history[\"acc\"],\n","                             'valid-acc': model.history.history[\"val_acc\"]}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Numbers of exp: 0, ce_weight: 0.00\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_7 (InputLayer)         (None, 3072)              0         \n","_________________________________________________________________\n","hidden_layer1 (Dense)        (None, 512)               1573376   \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 512)               2048      \n","_________________________________________________________________\n","hidden_layer2 (Dense)        (None, 256)               131328    \n","_________________________________________________________________\n","batch_normalization_20 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","hidden_layer3 (Dense)        (None, 128)               32896     \n","_________________________________________________________________\n","batch_normalization_21 (Batc (None, 128)               512       \n","_________________________________________________________________\n","output (Dense)               (None, 10)                1290      \n","=================================================================\n","Total params: 1,742,474\n","Trainable params: 1,740,682\n","Non-trainable params: 1,792\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-4c1f2bbadfa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0m將自定義的\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0m加入模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     model.fit(x_train, y_train, \n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-57bc2d666571>\u001b[0m in \u001b[0;36mcombined_loss\u001b[0;34m(y_true, y_pred, weight, e, gamma, alpha)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_fl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfocal_loss_fixed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcrossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mce_weights_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'function'"]}]},{"cell_type":"code","metadata":{"id":"0baRJyD-J_hO","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import matplotlib.cm as mplcm\n","import matplotlib.colors as colors\n","%matplotlib inline\n","NUM_COLORS = len(results.keys())\n","\n","cm = plt.get_cmap('gist_rainbow')\n","cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n","scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n","color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Loss\")\n","plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.show()\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Accuracy\")\n","plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.show()"],"execution_count":0,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機器學習裡常見的問題有\n",
    "    * 分類問題\n",
    "    * 預測問題\n",
    "    * 分群問題\n",
    "    * 降維問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類問題\n",
    "判斷垃圾郵件為一種常見的分類問題，目標為訓練一個模型分辨收到的電子郵件是垃圾郵件還是正常郵件。一個訓練好的分類模型對一封電子郵件的分類結果有以下4種:\n",
    "1. 實際上為垃圾郵件，系統判斷為垃圾郵件\n",
    "2. 實際上為垃圾郵件，系統判斷為正常郵件\n",
    "3. 實際上為正常郵件，系統判斷為垃圾郵件\n",
    "4. 實際上為正常郵件，系統判斷為正常郵件 \n",
    "\n",
    "其中1,4為分類正確，2,3為分類錯誤。可以用以下表格 (Confusion Matrix) 表示:\n",
    "\n",
    "| 預測值/真實值 |    垃圾郵件    |    正常郵件    |\n",
    "| ------------ |   ----------  |   ----------  |\n",
    "|    垃圾郵件  | True Positive (TP)  |  False Positive (FP) |\n",
    "|    正常郵件  | False Negative (FN) |  True Negative (TN) |\n",
    "\n",
    "假設有100封郵件，其中TP = 5, FP = 5, FN = 0, TN = 90\n",
    "也就是說正常郵件有 FN + TN = 95，垃圾郵件有 TP + FP = 5封。\n",
    "\n",
    "模型判斷正常的有 TP + TN = 95封，\n",
    "模型判斷錯誤的有 FN + FP = 5封。\n",
    "\n",
    "以下介紹在**分類問題**裡常見的評估指標 (Evaluation Metrics):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Accuracy (準確度)\n",
    "準確度為模型判斷正確的機率，公式如下\n",
    " \n",
    "$$ Accuracy = \\frac{TP+TN}{TP+FP+TN+FN} $$\n",
    "\n",
    "用分類垃圾郵件的例子可以算出 $ Accuracy = \\frac{95}{100}=0.95 $\n",
    " \n",
    "看起來結果不錯，訓練出來的模型有9成5的準確度。\n",
    "\n",
    "假設我們現在有一個分類器，分類器的邏輯很簡單，所有信件都判斷為正常信件，則該分類器的準確度有9成，看起來也不錯，但其實這個情況下所有的垃圾郵件都分類錯誤了，該分類器可以說毫無用處!!\n",
    "\n",
    "會造成這種情況的原因為垃圾郵件在所有郵件裡的比例很低，大部分的郵件都是正常郵件，導致準確度不是一個適合的評估指標。上述的情況為Accuracy Paradox，常在非均衡數據集中遇到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Precision (精確度)\n",
    "Precision的公式為**分辨正確的數量/分辨為垃圾郵件的數量**，如下\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "用分類垃圾郵件的例子可以算出 $ Precision = \\frac{5}{10}=0.5 $，表示模型找出的垃圾郵件裡只有一半是真的垃圾郵件。\n",
    "\n",
    "在線上影音平台，推薦系統和搜尋引擎是相當重要的功能，一般平台上提供著幾千部影片，用戶往往無法馬上找到自己想看的影片，因此推薦系統會希望推薦給用戶的影片清單都是用戶想看的，搜尋引擎會希望搜尋出來的影片都與**搜尋關鍵字**是相關的，因此常使用Precision當作評估指標，計算推薦出來的清單裡有多少比例是用戶想看的影片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recall (召回率)\n",
    "Recall的公式為**分辨正確的數量/真的為垃圾郵件的數量**，如下\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP+FN} $$\n",
    "\n",
    "用分類垃圾郵件的例子可以算出 $ Recall = \\frac{5}{5}=1 $，表示將全部的垃圾郵件都找了出來。\n",
    "\n",
    "在推薦系統的情境下，表示系統推薦出來的清單裡用戶想看的影片占用戶全部想看的影片比例。\n",
    "\n",
    "詳細的理解可參考https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. F1-Measure\n",
    "在使用Precision跟Recall上，會因使用的場景的不同而特別看重其中一個，像是門禁系統會看重Precision，寧願讓員工多辨識幾次也不能讓外人進入。而在分辨癌症的情境下，會想將有癌症的人都找出來，不想有遺漏，就會看重Recall。\n",
    "\n",
    "有一種折衷的方式是將Precision跟Recall組合起來，公式如下:\n",
    "\n",
    "$$ F_1 = \\frac{2}{1/Precision+1/Recall} = 2*\\frac{Precision\\times Recall}{Precision+Recall} $$\n",
    "\n",
    "近似於Precision和Recall的加權平均，在分類垃圾郵件的例子可以算出 $ F_1 = 2*\\frac{0.5\\times 1}{0.5+1} = \\frac{2}{3} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MCC (Matthews Correlation Coefficient)\n",
    "實際上在Accuracy Paradox的問題下，Precision和Recall和F1都無法很好的解決這個問題，因此Brian W. Matthews提出了MCC，公式如下:\n",
    "\n",
    "$$ MCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}} $$\n",
    "\n",
    "MCC為真實值跟預測值的相關係數，當MCC=1時表示分類器是完美的，=0時表示分類器的表現跟隨機一樣，=-1表示預測值跟真實值完全不一致。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. AUC (Area Under Curve)\n",
    "AUC為介於0至1之間的評估指標，跟AUC=1時表示分類器是完美的，=0.5時表示分類器的表現跟隨機一樣，越接近0表示模型越不好。\n",
    "\n",
    "在認識AUC之前得先介紹ROC(Receiver Operating Characteristic)，我們假設\n",
    "\n",
    "$TPR=\\frac{TP}{TP+FN}=\\frac{TP}{P}$ 為實際上為垃圾郵件裡被判斷為垃圾郵件的比例，希望這個值越大越好\n",
    "\n",
    "$FPR=\\frac{FP}{FP+TN}=\\frac{FP}{N}$ 為實際上為正常郵件裡被判斷為垃圾郵件的比例，希望這個值越小越好\n",
    "\n",
    "一般的分類模型對一筆資料的預測值為一個數值，我們會設定一個閥值(threshold ) $\\theta \\in (-\\infty,\\infty)$\n",
    "，當預測值大於$\\theta$時判定為正分類(垃圾郵件)，反之為負分類。ROC為以(FPR,TPR)為x,y軸在不同$\\theta$下劃出的線圖，當畫出來的線圖越靠近左上方則模型表現越好，越靠近右下方模型表現越差，詳細說明可以參考https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf\n",
    "\n",
    "介紹完ROC，可以回來介紹AUC，AUC為隨機抽取一組正負樣本(垃圾郵件和正常郵件)，正樣本的預測值會大於負樣本的預測值的機率，且該值等於ROC曲線與X軸之間的面積，詳細計算可以參考:http://www.win-vector.com/blog/2013/01/more-on-rocauc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. MAP (Mean Average Precision)\n",
    "AP值是對**正確的結果要優先出現**的衡量指標，在推薦系統和搜尋引擎上我們會希望用戶越喜歡或搜尋結果越相關的影片排在越前面，因此可以參考這個指標。AP值的計算與AUC相似，AUC是在不同$\\theta$下以(FPR,TPR)畫的曲線下面積，AP則是在不同$\\theta$下以(Recall,Percision)畫的曲線下面積，MAP則為多次實驗下AP的平均，詳細計算可參考:https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. nDCG (Discounted Cumulative Gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
